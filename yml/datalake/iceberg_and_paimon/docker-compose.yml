#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

version: "3"

services:
  spark:
    image: tabulario/spark-iceberg
    platform: linux/arm64
    container_name: data-warehouse-spark
    hostname: demo-spark-iceberg
    build: spark/
    volumes:
      - ./packages/jars/paimon-spark-3.5-0.8.0.jar:/opt/spark/jars/paimon-spark-3.5-0.8.0.jar
      - ./packages/jars/paimon-s3-0.8.0.jar:/opt/spark/jars/paimon-s3-0.8.0.jar
      - ./data/table:/opt/data
      - ./data/spark-conf:/opt/spark/conf
      - ./sql/prepare_data.sql:/opt/sql/prepare_data.sql
    depends_on:
      - rest
      - minio
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
    networks:
      - demo-iceberg

  rest:
    image: tabulario/iceberg-rest
    platform: linux/arm64
    container_name: data-warehouse-iceberg-rest
    ports:
      - ${REST_CATALOG_PORT}:8181
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
      - CATALOG_WAREHOUSE=s3://warehouse/wh/
      - CATALOG_IO__IMPL=org.apache.iceberg.aws.s3.S3FileIO
      - CATALOG_S3_ENDPOINT=http://minio:9000
    networks:
      - demo-iceberg
    volumes:
      - './packages/jdk1.8.0_421:/opt/jdk1.8.0_421'
      - './packages/doris-bin:/opt/doris-bin'
      - './scripts:/opt/scripts'

  minio:
    image: minio/minio
    platform: linux/arm64
    container_name: data-warehouse-minio
    ports:
      - ${MINIO_API_PORT}:9000
      - ${MINIO_UI_PORT}:9001
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=password
      - MINIO_DOMAIN=minio
    networks:
      demo-iceberg:
        aliases:
          - warehouse.minio
    command: ["server", "/data", "--console-address", ":9001"]

  mc:
    depends_on:
      - minio
    image: minio/mc:RELEASE.2024-10-02T08-27-28Z-cpuv1
    platform: linux/arm64
    container_name: data-warehouse-mc
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
    networks:
      - demo-iceberg
    entrypoint: >
      /bin/sh -c "
      until (/usr/bin/mc config host add minio http://minio:9000 admin password) do echo '...waiting...' && sleep 1; done;
      /usr/bin/mc rm -r --force minio/warehouse;
      /usr/bin/mc mb minio/warehouse;
      /usr/bin/mc policy set public minio/warehouse;
      tail -f /dev/null
      "

  jobmanager:
    image: flink:1.18.0
    platform: linux/arm64
    container_name: data-warehouse-jobmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
    ports:
      - "8082:8081"
    command: jobmanager
    depends_on:
      - rest
      - minio
    volumes:
      - ./packages/jars/flink-connector-jdbc-3.1.2-1.18.jar:/opt/flink/lib/flink-connector-jdbc-3.1.2-1.18.jar
      - ./packages/jars/flink-shaded-hadoop-2-uber-2.8.3-10.0.jar:/opt/flink/lib/flink-shaded-hadoop-2-uber-2.8.3-10.0.jar
      - ./packages/jars/flink-s3-fs-hadoop-1.18.0.jar:/opt/flink/plugins/s3-fs-hadoop/flink-s3-fs-hadoop-1.18.0.jar
      - ./packages/jars/iceberg-flink-runtime-1.18-1.5.2.jar:/opt/flink/lib/iceberg-flink-runtime-1.18-1.5.2.jar
      - ./packages/jars/iceberg-aws-bundle-1.5.2.jar:/opt/flink/lib/iceberg-aws-bundle-1.5.2.jar
      - ./packages/jars/paimon-flink-1.18-0.8.0.jar:/opt/flink/lib/paimon-flink-1.18-0.8.0.jar
      - ./packages/jars/paimon-s3-0.8.0.jar:/opt/flink/lib/paimon-s3-0.8.0.jar
      - ./sql/init_tables.sql:/opt/flink/sql/init_tables.sql
      - ./data/flink-conf:/opt/flink/conf
    networks:
      - demo-iceberg
    deploy:
      replicas: 1

  taskmanager:
    image: flink:1.18.0
    platform: linux/arm64
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
    depends_on:
      - jobmanager
    command: taskmanager
    volumes:
      - ./packages/jars/flink-connector-jdbc-3.1.2-1.18.jar:/opt/flink/lib/flink-connector-jdbc-3.1.2-1.18.jar
      - ./packages/jars/flink-shaded-hadoop-2-uber-2.8.3-10.0.jar:/opt/flink/lib/flink-shaded-hadoop-2-uber-2.8.3-10.0.jar
      - ./packages/jars/flink-s3-fs-hadoop-1.18.0.jar:/opt/flink/plugins/s3-fs-hadoop/flink-s3-fs-hadoop-1.18.0.jar
      - ./packages/jars/iceberg-flink-runtime-1.18-1.5.2.jar:/opt/flink/lib/iceberg-flink-runtime-1.18-1.5.2.jar
      - ./packages/jars/iceberg-aws-bundle-1.5.2.jar:/opt/flink/lib/iceberg-aws-bundle-1.5.2.jar
      - ./packages/jars/paimon-flink-1.18-0.8.0.jar:/opt/flink/lib/paimon-flink-1.18-0.8.0.jar
      - ./packages/jars/paimon-s3-0.8.0.jar:/opt/flink/lib/paimon-s3-0.8.0.jar
    networks:
      - demo-iceberg
    deploy:
      replicas: 2

  doris:
    image: yagagagaga/doris-standalone:2.1.5
    platform: linux/arm64
    container_name: data-warehouse-doris
    ports:
      - "8030:8030"
      - "8040:8040"
      - "9030:9030"
    volumes:
      - ./doris/doris_fe_meta:/opt/doris/fe/meta
      - ./doris/doris_be_storage:/opt/doris/be/storage
    networks:
      - demo-iceberg

  mysql:
    image: mysql:8.0.32
    platform: linux/arm64
    container_name: data-warehouse-mysql
    environment:
      - MYSQL_ROOT_PASSWORD=666666
    ports:
      - "3306:3306"
    networks:
      - demo-iceberg


networks:
  demo-iceberg:
    ipam:
      driver: default
